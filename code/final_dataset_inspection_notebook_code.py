from collections import Counter
import json
import pathlib
import random
from timeit import default_timer as timer

import ipywidgets as widgets

import mturk_utils
import near_duplicate_data


def get_filenames_by_wnid(data, all_wnids):
    image_filenames = data['image_filenames']
    filenames_by_wnid = {}
    for wnid in all_wnids:
        filenames_by_wnid[wnid] = []
    for img, wnid in image_filenames:
        filenames_by_wnid[wnid].append(img)
    return filenames_by_wnid


def load_dataset_and_print_info(dataset_name, imgnet, cds, mturk, ndc):
    with open('../data/datasets/{}'.format(dataset_name), 'r') as f:
        data = json.load(f)
    assert dataset_name == data['output_filename']
    print('Dataset {}\n'.format(data['output_filename']))
    print('Generated by {} at {}'.format(data['username'], data['time_string']))
    print('Sampling function: {} (seed {})\n'.format(data['sampling_function'], data['seed']))

    print('Futher parameters:')
    keys_to_show = ['selection_frequency_threshold',
                    'min_num_annotations',
                    'near_duplicate_review_targets',
                    'is_valid',
                    'starting_from',
                    'wnid_thresholds']
    for k in keys_to_show:
        if k in data:
            print('    {}: {}'.format(k, data[k]))

    image_filenames = data['image_filenames']
    filenames_by_wnid = get_filenames_by_wnid(data, imgnet.class_info_by_wnid.keys())
    class_freq_counter = Counter([len(x) for x in filenames_by_wnid.values()])

    print('\n{} images for {} wnids\n'.format(len(image_filenames), len(filenames_by_wnid)))
    for class_size, freq in class_freq_counter.most_common(1000):
        print('{} wnids have {} images'.format(freq, class_size))
    
    print('\nNumber of unique image filenames: {}'.format(len(set([x[0] for x in image_filenames]))))
    
    num_candidate_images = 0
    num_imagenet_images = 0
    all_imagenet_images = set(imgnet.get_all_image_names())
    test_filenames_set = set(imgnet.test_filenames)
    num_train_images = 0
    num_val_images = 0
    num_test_images = 0
    for img, wnid in image_filenames:
        if img in cds.all_candidates:
            num_candidate_images += 1
            assert wnid == cds.all_candidates[img]['wnid']
        elif img in all_imagenet_images:
            if img in imgnet.train_imgs_by_wnid[wnid]:
                num_train_images += 1
            elif img in imgnet.val_imgs_by_wnid[wnid]:
                num_val_images += 1
            elif img in test_filenames_set:
                num_train_images += 1
            else:
                raise ValueError()
        else:
            raise ValueError('Unknown source of image {}'.format(img))
    print('\n{} images are candidate images'.format(num_candidate_images))
    print('{} images are ImageNet images'.format(num_imagenet_images))
    print('    {} training images'.format(num_train_images))
    print('    {} val images'.format(num_val_images))
    print('    {} test images'.format(num_test_images))

    wnids_ok = True
    for wnid in imgnet.class_info_by_wnid.keys():
        if wnid not in filenames_by_wnid:
            print('ImageNet wnid {} missing in the dataset'.format(wnid))
            wnids_ok = False
    for wnid in filenames_by_wnid.keys():
        if wnid not in imgnet.class_info_by_wnid:
            print('Dataset wnid {} not in ImageNet'.format(wnid))
            wnids_ok = False
    if wnids_ok:
        print('\nDataset wnids match the ImageNet wnids')

    blacklisted_candidates = []
    for img, _ in image_filenames:
        if img in cds.blacklist:
            blacklisted_candidates.append(img)
    print('\nThe dataset contains {} blacklisted candidates'.format(len(blacklisted_candidates)))

    min_num_assignments = 1000000
    for img, wnid in image_filenames:
        cur_num_assignments = 0
        if img in mturk.image_num_assignments and wnid in mturk.image_num_assignments[img]:
            cur_num_assignments = mturk.image_num_assignments[img][wnid]
        min_num_assignments = min(min_num_assignments, cur_num_assignments)
    print('\nThe minimum number of assignments for an image in the dataset is {}'.format(min_num_assignments))

    wnid_thresholds = {}
    if 'wnid_thresholds' in data:
        wnid_thresholds = data['wnid_thresholds']
    min_selection_frequency = 2.0
    min_selection_frequency_non_special = 2.0
    avg_selection_frequency = 0.0
    num_filenames_with_selection_frequency = 0
    for img, wnid in image_filenames:
        if img in mturk.image_fraction_selected and wnid in mturk.image_fraction_selected[img]:
            cur_selection_frequency = mturk.image_fraction_selected[img][wnid]
            min_selection_frequency = min(min_selection_frequency, cur_selection_frequency)
            avg_selection_frequency += cur_selection_frequency
            num_filenames_with_selection_frequency += 1
            if wnid not in wnid_thresholds:
                    min_selection_frequency_non_special = min(min_selection_frequency_non_special,
                                                              cur_selection_frequency)
    avg_selection_frequency /= num_filenames_with_selection_frequency
    print('\nThe minimum image selection frequency of an image in the dataset is {}'.format(min_selection_frequency))
    print('    ({} among wnids without a special threshold)'.format(min_selection_frequency_non_special))
    print('    ({} images do not have a selection frequency)'.format(len(image_filenames) - num_filenames_with_selection_frequency))
    print('The average image selection frequency of the images in the dataset is {:.2f}'.format(avg_selection_frequency))
        
    near_duplicates = []
    review_thresholds = {}
    for metric_name in near_duplicate_data.metric_names:
        review_thresholds[metric_name] = 1e100
    for img, _ in image_filenames:
        if img in ndc.is_near_duplicate and ndc.is_near_duplicate[img]:
            near_duplicates.append(img)
        for metric_name in near_duplicate_data.metric_names:
            if img in ndc.review_threshold and metric_name in ndc.review_threshold[img]:
                review_thresholds[metric_name] = min(review_thresholds[metric_name], ndc.review_threshold[img][metric_name])
            else:
                review_thresholds[metric_name] = min(review_thresholds[metric_name], 0.0)
    print('\nThe dataset contains {} near-duplicates'.format(len(near_duplicates)))
    print('Review thresholds:')
    for metric_name in near_duplicate_data.metric_names:
        print('    {}: {:e}'.format(metric_name, review_thresholds[metric_name]))

    assert dataset_name.endswith('.json')
    review_filename = dataset_name[:-5] + '_review.json'
    review_filepath = pathlib.Path('../data/dataset_reviews/' + review_filename)
    review_filepath = review_filepath.resolve()
    print()
    if review_filepath.is_file():
        print('Loading review data from {}'.format(review_filepath))
        with open(review_filepath, 'r') as f:
            review_data = json.load(f)
    else:
        print('Saving a new review data file to {}'.format(review_filepath))
        review_data = {}
        for wnid in filenames_by_wnid.keys():
            review_data[wnid] = {'reviewed': False, 'problematic': False}
        with open(review_filepath, 'w') as f:
            json.dump(review_data, f, indent=2, sort_keys=True)
    print()
    num_reviewed = len([x for x in review_data.items() if x[1]['reviewed']])
    print('Number of reviewed wnids: {}'.format(num_reviewed))
    num_problematic = len([x for x in review_data.items() if x[1]['problematic']])
    print('Number of problematic wnids: {}'.format(num_problematic))

    return data, review_data, review_filepath


def generate_review_ui(*, num_wnids_to_show,
                       starting_wnid,
                       data,
                       review_data,
                       imgnet,
                       cds,
                       loader,
                       ndc,
                       num_val_images_per_wnid=10,
                       image_filter,
                       show_reviewed):
    all_wnids = sorted(imgnet.class_info_by_wnid.keys())
    start_index = all_wnids.index(starting_wnid)
    wnids_to_review = {}
    filenames_by_wnid = get_filenames_by_wnid(data, imgnet.class_info_by_wnid.keys())
    for ii in range(start_index, len(all_wnids)):
        cur_wnid = all_wnids[ii]
        if show_reviewed or not review_data[cur_wnid]['reviewed']:
            cids_to_show = list(filenames_by_wnid[cur_wnid])
            if image_filter == 'only_bad':
                cids_to_show = [x for x in cids_to_show if x in cds.blacklist or ndc.is_near_duplicate[x]]
            else:
                assert image_filter == 'all'
            if len(cids_to_show) > 0:
                wnids_to_review[cur_wnid] = cids_to_show
        if len(wnids_to_review) >= num_wnids_to_show:
            break
    return show_wnids(wnids_to_review=wnids_to_review,
                      data=data,
                      review_data=review_data,
                      imgnet=imgnet,
                      cds=cds,
                      loader=loader,
                      num_val_images_per_wnid=num_val_images_per_wnid)


def show_wnids(*, wnids_to_review,
               data,
               review_data,
               imgnet,
               cds,
               loader,
               num_val_images_per_wnid=10):
    val_images_to_show = {}
    images_to_load = []
    captions = {}
    blacklist_checkboxes = {}
    for wnid, wnid_cids in wnids_to_review.items():
        val_images_to_show[wnid] = random.sample(imgnet.val_imgs_by_wnid[wnid], num_val_images_per_wnid)
        images_to_load.extend(val_images_to_show[wnid])
        images_to_load.extend(wnid_cids)
        for img in wnid_cids:
            is_blacklisted = img in cds.blacklist
            blacklist_checkboxes[img] = widgets.Checkbox(value=is_blacklisted, description='', indent=False, layout={'width': '30px'})
            blacklist_label = widgets.Label('Blacklist:')
            captions[img] = [img,
                             cds.all_candidates[img]['date_taken'],
                             widgets.HBox([blacklist_label, blacklist_checkboxes[img]])]
        for img in val_images_to_show[wnid]:
            captions[img] = [img]
    print('Loading image data ... ', end='')
    start = timer()
    image_data = loader.load_image_bytes_batch(set(images_to_load), size='scaled_256', verbose=False)
    end = timer()
    print('done, took {} seconds'.format(end - start), flush=True)

    widgets_to_show = []
    image_size = '180px'
    image_box_padding = '3px'

    review_checkboxes = {}
    problematic_checkboxes = {}
    near_duplicate_text_fields = {}

    for wnid, wnid_cids in wnids_to_review.items():
        wnid_label = widgets.Label(value=wnid)
        wnid_label.add_class('wnid_heading')
        widgets_to_show.append(wnid_label)
        synset_label = widgets.Label(value=', '.join(imgnet.class_info_by_wnid[wnid].synset))
        widgets_to_show.append(synset_label)
        gloss_label = widgets.Label(value=imgnet.class_info_by_wnid[wnid].gloss)
        widgets_to_show.append(gloss_label)
        cur_filenames_in_order = list(sorted(wnid_cids, key=lambda x: cds.all_candidates[x]['date_taken']))
        dataset_grid = mturk_utils.show_image_grid(cur_filenames_in_order, captions, image_data, num_cols=5, max_width=image_size, max_height=image_size, image_box_padding=image_box_padding)
        widgets_to_show.append(dataset_grid)
        val_grid = mturk_utils.show_image_grid(val_images_to_show[wnid], captions, image_data, num_cols=5, max_width=image_size, max_height=image_size, image_box_padding=image_box_padding)
        widgets_to_show.append(val_grid)
        #wrong_class_text_fields[wnid] = widgets.Text(value='', description='', layout={'width': '800px'})
        #widgets_to_show.append(widgets.HBox([widgets.Label('Wrong class images:'), wrong_class_text_fields[wnid]]))
        near_duplicate_text_fields[wnid] = widgets.Text(value='', description='', layout={'width': '800px'})
        widgets_to_show.append(widgets.HBox([widgets.Label('Near-duplicate set:'), near_duplicate_text_fields[wnid]]))
        checkbox_label = widgets.Label(value=wnid + ' (above): ')
        reviewed_checkbox = widgets.Checkbox(review_data[wnid]['reviewed'], description='reviewed')
        review_checkboxes[wnid] = reviewed_checkbox
        problematic_checkbox = widgets.Checkbox(review_data[wnid]['problematic'], description='problematic')
        problematic_checkboxes[wnid] = problematic_checkbox
        checkbox_hbox = widgets.HBox([checkbox_label, reviewed_checkbox, problematic_checkbox])
        widgets_to_show.append(checkbox_hbox)

    return widgets.VBox(widgets_to_show), review_checkboxes, problematic_checkboxes, blacklist_checkboxes, near_duplicate_text_fields


def compute_splitting_points(review_data, split_sizes):
    unreviewed_wnids = list(sorted([x[0] for x in review_data.items() if not x[1]['reviewed']]))
    splitting_points = []
    cur_offset = 0
    res_split_sizes = []
    for next_split_size in split_sizes:
        assert cur_offset < len(unreviewed_wnids)
        splitting_points.append(unreviewed_wnids[cur_offset])
        cur_offset += next_split_size
        res_split_sizes.append(next_split_size)
    num_remaining_wnids = len(unreviewed_wnids) - cur_offset
    splitting_points.append(unreviewed_wnids[cur_offset])
    res_split_sizes.append(num_remaining_wnids)
    return zip(splitting_points, res_split_sizes)
