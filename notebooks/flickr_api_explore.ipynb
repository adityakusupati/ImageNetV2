{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "\n",
    "import concurrent\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import urllib\n",
    "\n",
    "import flickrapi\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import tqdm\n",
    "\n",
    "repo_root = os.path.join(os.getcwd(), '../code')\n",
    "sys.path.append(repo_root)\n",
    "\n",
    "import candidate_data\n",
    "import imagenet\n",
    "import mturk_data\n",
    "import mturk_utils\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from local file /Users/ludwig/research/deep_learning/imagenet_2/data/cache/metadata/imagenet_metadata_2018-09-14_01-26-58_UTC.pickle ... done\n",
      "Loaded 167399 unique candidates from 86 search result JSON file(s).\n",
      "    /Users/ludwig/research/deep_learning/imagenet_2/data/search_results/...\n",
      "        2018-07-31_flickr_search_result_vaishaal_class_1_153.json\n",
      "        2018-08-20-16-10-18_becca.json\n",
      "        2018-08-25-11-43-09_becca.json\n",
      "        2018-08-27-22-53-45_becca.json\n",
      "        2018-08-30-02-40-26_becca.json\n",
      "        2018-08-30-18-46-35_becca.json\n",
      "        2018-08-30-19-31-10_becca.json\n",
      "        2018-09-04-17-03-01_becca.json\n",
      "        2018-09-04-17-36-03_becca.json\n",
      "        2018-09-05-16-16-14_becca.json\n",
      "        ...\n",
      "    There were 65500 duplicate occurences.\n",
      "    Ignored 0 candidate entries because they are on the blacklist (blacklist size: 1956).\n"
     ]
    }
   ],
   "source": [
    "imgnet = imagenet.ImageNetData()\n",
    "cds = candidate_data.CandidateData(load_metadata_from_s3=False, exclude_blacklisted_candidates=False)\n",
    "\n",
    "cds_by_flickr_id = {}\n",
    "for cand in cds.all_candidates.values():\n",
    "    cur_flickr_id = cand['id_search_engine']\n",
    "    if cur_flickr_id not in cds_by_flickr_id:\n",
    "        cds_by_flickr_id[cur_flickr_id] = []\n",
    "    cds_by_flickr_id[cur_flickr_id].append(cand)\n",
    "\n",
    "#mturk = mturk_data.MTurkData(live=True,\n",
    "#                             load_assignments=True,\n",
    "#                             source_filenames_to_ignore=mturk_data.main_collection_filenames_to_ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/flickr_api_keys.json', 'r') as f:\n",
    "    flickr_api_keys = json.load(f)\n",
    "    api_key = flickr_api_keys[0]\n",
    "    api_secret = flickr_api_keys[1]\n",
    "flickr = flickrapi.FlickrAPI(api_key, api_secret, format='etree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec15363b3a10483e8f96482698bf69b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='API calls', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 152 results, skipped 48 duplicates we already have\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce8c887a83d43d7b39a243ba7cbde9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloads', max=152), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "149739d9946e463093116c2b5eff8b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00H\\xâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "search_keys = ['torch -olympic']\n",
    "\n",
    "cur_wnid = 'n04456115'\n",
    "\n",
    "max_images = 200\n",
    "\n",
    "num_duplicate_skipped = 0\n",
    "good_url_types = ['url_o', 'url_k', 'url_h', 'url_b', 'url_c', 'url_z', 'url_-']\n",
    "good_url_types.reverse()\n",
    "result_urls = {}\n",
    "result_search_keys = {}\n",
    "\n",
    "for search_key in tqdm.tqdm_notebook(search_keys, desc='API calls'):\n",
    "    search_set = flickr.walk(\n",
    "        text=search_key,\n",
    "        extras = 'date_upload,date_taken,o_dims,url_s,url_q,url_t,url_m,url_n,url_-,url_z,url_c,url_b,url_h,url_k,url_o',\n",
    "        sort = 'date-posted-asc',\n",
    "        max_taken_date = '2014-07-11',\n",
    "        max_uploaded_date = '2014-07-11',\n",
    "        min_taken_date = '2012-07-11',\n",
    "        min_uploaded_date = '2012-07-11',\n",
    "        per_page=1000)\n",
    "\n",
    "    result_iterator = itertools.islice(search_set, max_images)\n",
    "\n",
    "    for photo in result_iterator:\n",
    "        cur_flickr_id = photo.get('id')\n",
    "        if cur_flickr_id is None:\n",
    "            print('ERROR: no id returned from flickr')\n",
    "            continue\n",
    "        url = None\n",
    "        for url_type in good_url_types:\n",
    "            cur_url = photo.get(url_type)\n",
    "            if cur_url is not None:\n",
    "                url = cur_url\n",
    "                selected_url_type = url_type\n",
    "                break\n",
    "        if url is None:\n",
    "            print('ERROR: id {} does not have a good URL'.format(cur_flickr_id))\n",
    "            continue\n",
    "        if cur_flickr_id in cds_by_flickr_id:\n",
    "            if cur_wnid in [x['wnid'] for x in cds_by_flickr_id[cur_flickr_id]]:\n",
    "                num_duplicate_skipped += 1\n",
    "                continue\n",
    "        result_urls[cur_flickr_id] = url\n",
    "        if cur_flickr_id not in result_search_keys:\n",
    "            result_search_keys[cur_flickr_id] = []\n",
    "        result_search_keys[cur_flickr_id].append(search_key)\n",
    "\n",
    "print('Found {} results, skipped {} duplicates we already have'.format(len(result_urls), num_duplicate_skipped))\n",
    "\n",
    "\n",
    "def download_image(flickr_id):\n",
    "    return urllib.request.urlopen(result_urls[flickr_id]).read()\n",
    "\n",
    "result_images = {}\n",
    "pbar = tqdm.tqdm_notebook(total=len(result_urls), desc='Downloads')\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n",
    "    future_to_id = {executor.submit(download_image, flickr_id): flickr_id for flickr_id in result_urls.keys()}\n",
    "    for future in concurrent.futures.as_completed(future_to_id):\n",
    "        flickr_id = future_to_id[future]\n",
    "        try:\n",
    "            result_images[flickr_id] = future.result()\n",
    "        except Exception as exc:\n",
    "            print('Id {} generated an exception: {}'.format(flickr_id, exc))\n",
    "            raise exc\n",
    "        pbar.update(1)\n",
    "pbar.close()\n",
    "\n",
    "captions = {}\n",
    "for flickr_id, url in result_urls.items():\n",
    "    captions[flickr_id] = [url, ', '.join(result_search_keys[flickr_id])]\n",
    "\n",
    "mturk_utils.show_image_grid(result_urls.keys(), captions, result_images, num_cols=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
