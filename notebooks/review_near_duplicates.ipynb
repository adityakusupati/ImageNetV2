{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Initializing the notebook\n",
    "Run this cell only once to start reviewing. It is not necessary to relaod this cell in order to load the results from other reviewers (this happens in the next cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Reading from local file /Users/becca/git/imagenet_2/data/cache/metadata/imagenet_metadata_2018-09-14_01-26-58_UTC.pickle ... done\n",
      "Loaded 178264 unique candidates from 146 search result JSON file(s).\n",
      "    /Users/becca/git/imagenet_2/data/search_results/...\n",
      "        2018-07-31_flickr_search_result_vaishaal_class_1_153.json\n",
      "        2018-08-20-16-10-18_becca.json\n",
      "        2018-08-25-11-43-09_becca.json\n",
      "        2018-08-27-22-53-45_becca.json\n",
      "        2018-08-30-02-40-26_becca.json\n",
      "        2018-08-30-18-46-35_becca.json\n",
      "        2018-08-30-19-31-10_becca.json\n",
      "        2018-09-04-17-03-01_becca.json\n",
      "        2018-09-04-17-36-03_becca.json\n",
      "        2018-09-05-16-16-14_becca.json\n",
      "        ...\n",
      "    There were 71506 duplicate occurences.\n",
      "    Ignored 15975 candidate entries because they are on the blacklist (blacklist size: 12860).\n",
      "Loaded 6751 HITs from 55 hit data JSON file(s) in 1 seconds.\n",
      "    /Users/becca/git/imagenet_2/data/mturk/hit_data_live/...\n",
      "        becca_hits_submitted_2018-09-20-21:12:45-PDT.json\n",
      "        becca_hits_submitted_2018-09-21-17:45:49-UTC.json\n",
      "        becca_hits_submitted_2018-09-21-22:55:10-UTC.json\n",
      "        ...\n",
      "    Ignored 7 filenames.\n",
      "    Ignored 4 HITs from the blacklist (blacklist size 4)\n",
      "/Users/becca/git/imagenet_2/data/cache/mturk_results/data_live_2018-11-08_19-58-56_UTC.pickle not available locally, downloading from S3 ... done\n",
      "Reading from local file /Users/becca/git/imagenet_2/data/cache/mturk_results/data_live_2018-11-08_19-58-56_UTC.pickle ... done\n",
      "Using pickled JSON data stored by ubuntu from /home/ubuntu/imagenet_2/data/mturk/hit_data_live locally\n",
      "    S3 source: s3://imagenet2datav2/mturk_results/data_live_2018-11-08_19-58-56_UTC.pickle\n",
      "    Ignored assignment data for 32 HITs\n",
      "    0 HITs do not have assignment data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53e8d8a761b34584bda8702845f26afe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='\\n<style>\\n.image_name {\\n    font-size: 8px;\\n    line-height: 12px;\\n    height: 12px;\\n}\\n</sty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current nearest neighbor statistics: \n",
      "104534 candidates for metric l2\n",
      "90812 candidates for metric dssim\n",
      "94891 candidates for metric fc7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import datetime\n",
    "import getpass\n",
    "from IPython.display import display\n",
    "from ipywidgets import widgets\n",
    "import json\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import tqdm\n",
    "\n",
    "repo_root = os.path.join(os.getcwd(), '../code')\n",
    "sys.path.append(repo_root)\n",
    "\n",
    "import candidate_data\n",
    "import imagenet\n",
    "import image_loader\n",
    "from near_duplicate_checker import print_nn_stats\n",
    "import mturk_utils\n",
    "import mturk_data\n",
    "from review_near_duplicates_notebook_code import *\n",
    "import utils\n",
    "\n",
    "imgnt = imagenet.ImageNetData()\n",
    "cds = candidate_data.CandidateData()\n",
    "mturk = mturk_data.MTurkData(live=True,\n",
    "                             load_assignments=True,\n",
    "                             source_filenames_to_ignore=mturk_data.main_collection_filenames_to_ignore)\n",
    "loader = image_loader.ImageLoader(imgnt, cds)\n",
    "display(mturk_utils.get_nn_review_css())\n",
    "\n",
    "with open('../data/metadata/nearest_neighbor_results.pickle', 'rb') as f:\n",
    "    nn_results = pickle.load(f)\n",
    "print('Current nearest neighbor statistics: ')\n",
    "print_nn_stats(nn_results)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Load existing near duplicates, reviews, and nearest neighbor information\n",
    "Re-run this cell after the files on disk have changed, e.g., after a `git pull`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current review statistics: \n",
      "1983 candidates for metric l2\n",
      "2588 candidates for metric dssim\n",
      "2370 candidates for metric fc7\n",
      "\n",
      "Number of candidate-metric pairs to review: 623\n",
      "Number of candidates with duplicates: 3654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load existing reviews\n",
    "# Reviews is a dictionary from candidate image to another dictionary \n",
    "# mapping from distance to reviewer name, time, threshold at which it was reviewed\n",
    "reviews = {}\n",
    "with open('../data/metadata/nearest_neighbor_reviews_v2.json', 'r') as f:\n",
    "    reviews = json.load(f)\n",
    "print('Current review statistics: ')\n",
    "print_nn_stats(reviews)\n",
    "print()\n",
    "\n",
    "thresholds = {\n",
    "    'l2' : 1.2e8,  #1.5e8\n",
    "    'dssim' : 0.2205,\n",
    "    'fc7' : 1.32e4  #1e4\n",
    "}\n",
    "cd_metric_pairs = get_cd_metric_pairs(nn_results, reviews, thresholds, cds)\n",
    "print('Number of candidate-metric pairs to review: {}'.format(len(cd_metric_pairs)))\n",
    "\n",
    "# Load existing near duplicates\n",
    "with open('../data/metadata/near_duplicates.json', 'r') as f:\n",
    "    near_duplicates = json.load(f)\n",
    "print('Number of candidates with duplicates: {}'.format(len(near_duplicates)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review nearest neighbors\n",
    "\n",
    "Go through the candidate pairs by changing `candidate_offset`.\n",
    "\n",
    "TODO: add functionality to show only candidate / nearest neighbor pairs that are not reviewed yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image data ... done, took 0.00027372699696570635 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98e36110ff1a421b9fa87c32704432fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Setting up image tabs', max=1), HTML(value=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following images have candidates below the threshold that were omitted:\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "565d62df54a54ba398004a2f71bb5e7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "candidate_offset = 0\n",
    "top_k = 10\n",
    "checkboxes, review_boxes = review_near_duplicates(cd_metric_pairs,\n",
    "                                                  nn_results,\n",
    "                                                  reviews,\n",
    "                                                  near_duplicates,                                     \n",
    "                                                  top_k,\n",
    "                                                  thresholds,\n",
    "                                                  candidate_offset,\n",
    "                                                  loader,\n",
    "                                                  cds,\n",
    "                                                  max_to_show=100,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are now 4442 images with at least one review entry.\n",
      "    Wrote to ../data/metadata/nearest_neighbor_reviews.json\n",
      "There are now 3654 candidates with near duplicates.\n",
      "    Wrote to ../data/metadata/near_duplicates.json\n"
     ]
    }
   ],
   "source": [
    "reviewer_name = getpass.getuser()\n",
    "cur_selected, cur_unselected = parse_checkboxes(checkboxes)\n",
    "near_duplicates = verify_checkboxes(checkboxes, cur_selected, cur_unselected, near_duplicates)\n",
    "reviews = parse_review_boxes(review_boxes, reviews, reviewer_name, thresholds)\n",
    "\n",
    "with open('../data/metadata/nearest_neighbor_reviews_v2.json', 'w') as f:\n",
    "    json.dump(reviews, f, indent=2)\n",
    "print('There are now {} images with at least one review entry.'.format(len(reviews)))\n",
    "print('    Wrote to ../data/metadata/nearest_neighbor_reviews.json')\n",
    "\n",
    "near_duplicates_to_save = get_near_duplicates_to_save(near_duplicates)\n",
    "num_near_duplicates = get_num_near_duplicates(near_duplicates_to_save)\n",
    "print('There are now {} candidates with near duplicates.'.format(num_near_duplicates))\n",
    "\n",
    "with open('../data/metadata/near_duplicates.json', 'w') as f:\n",
    "    json.dump(near_duplicates_to_save, f, indent=2, sort_keys=True)\n",
    "print('    Wrote to ../data/metadata/near_duplicates.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l2': {'reviewer': 'becca',\n",
       "  'date': '2018-10-12 15:01:34.232385',\n",
       "  'references': ['n04592741_9186.JPEG',\n",
       "   'ILSVRC2012_test_00075380.JPEG',\n",
       "   '8c3d391beeda1ee272c20378fa067c21427c7051',\n",
       "   '5abb22f22d7f066653f58355410fa307040c3912',\n",
       "   'n04275548_10476.JPEG',\n",
       "   'n03804744_34539.JPEG',\n",
       "   'n02134084_829.JPEG',\n",
       "   'n02058221_9499.JPEG',\n",
       "   '11e59de908f000f41cd975aab8070605d21dc36f',\n",
       "   'n02264363_1501.JPEG']},\n",
       " 'dssim': {'reviewer': 'becca',\n",
       "  'date': '2018-10-12 15:01:34.232402',\n",
       "  'references': ['ILSVRC2012_test_00009498.JPEG',\n",
       "   '1880cf9a3f28028066f77ad8044ef4f01ca78e4f',\n",
       "   'ILSVRC2012_test_00075380.JPEG',\n",
       "   'ILSVRC2012_val_00021872.JPEG',\n",
       "   'ILSVRC2012_test_00039843.JPEG',\n",
       "   '8c3d391beeda1ee272c20378fa067c21427c7051',\n",
       "   '5abb22f22d7f066653f58355410fa307040c3912',\n",
       "   '3d351fcd1cd706573034f1d4283500cc569ff48a',\n",
       "   'ILSVRC2012_test_00016870.JPEG',\n",
       "   '0b902bc90ea22cc91c7e89e310807010ca0ce1ed']},\n",
       " 'fc7': {'reviewer': 'becca',\n",
       "  'date': '2018-10-17 11:37:38.378699',\n",
       "  'references': ['ILSVRC2012_test_00086024.JPEG',\n",
       "   'n02120079_995.JPEG',\n",
       "   'n02134084_17358.JPEG',\n",
       "   'n01784675_5690.JPEG',\n",
       "   'n01773549_3633.JPEG',\n",
       "   'n01796340_648.JPEG',\n",
       "   'n02692877_2129.JPEG',\n",
       "   'n01616318_2493.JPEG',\n",
       "   'n02641379_1547.JPEG',\n",
       "   'n02317335_12368.JPEG']}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[\"5cec40d17d6d478a66516d237f1702bb3b5d500b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
